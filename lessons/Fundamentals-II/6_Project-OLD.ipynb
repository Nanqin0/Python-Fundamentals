{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Project\n",
    "\n",
    "* * * \n",
    "\n",
    "### Icons Used In This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive excersise. We'll work through these in the workshop!<br>\n",
    "üí≠ **Reflection**: Helping you think about programming.<br>\n",
    "‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>\n",
    "\n",
    "### Learning Objectives\n",
    "1. [üöÄ Project](#project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Project\n",
    "\n",
    "### Data: Airline Tweets\n",
    "In this section, we will go through an example analysis of tweets about airlines. We will bring together the basic programming, loading data, and statistical analysis/visualization techniques from this workshop to analyze airline tweets. \n",
    "\n",
    "First, let's import the packages to use in this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting the data\n",
    "\n",
    "Before we can get our data, you should know something more about **filepaths**. \n",
    "\n",
    "A filepath is the location of a file on your system. There are two kinds of filepaths:\n",
    "\n",
    "* **absolute**: The filepath from the top level directory (or folder).\n",
    "    * For Macs, these begin with a forward slash, followed by folders separated by a **forward slash**. E.g. `/Users/[USERNAME]/directory/subdirectory/file`.\n",
    "    * For Windows, these begin with a backward slash or, more commonly, a volume, e.g. `C:\\Documents\\directory\\subdirectory\\file`. Note the **backward slash** to separate folders.\n",
    "* **relative**: The filepath relative to the current working directory (i.e. notebook location). Common locations include:\n",
    "    * File in same folder: `./file` or `file` (`.` means 'here').\n",
    "    * Subfolder: `subfolder/file`.\n",
    "    * Higher folder: `../sisterfolder/file` (`..` means 'go up one level in the directory')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are figuring out what filepath to use, you can use `os.listdir([PATH])` to list all subdirectories in a path. For example, let's see what directories are available to us in the current folder (noted with a dot `.`).\n",
    "\n",
    "üîî **Question**: In this current folder we're checking out, which items are folders and which are files? (**Hint:** You can double check by looking at the files in JupyterLab/ Jupyter Notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up the items in the folder after moving up one level works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Our Dataset: Airline Tweets\n",
    "\n",
    "The dataset we will use is from the [Airline tweets sentiment dataset](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment?resource=download), which contains tweets that tag one of several major airlines. The dataset also includes information about the tweet location and time, the airline mentioned, and the sentiment of the tweet.\n",
    "\n",
    "There are several files in the \"airline\" subfolder of the \"data\" folder in our Python Fundamentals repository. \n",
    "\n",
    "üîî **Question**: Use the File Browser to the left of your screen. Can you find the \"airline\" folder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Import Data\n",
    "\n",
    "Use `os.listdir()` to see the files in the \"airlines\" folder. \n",
    "\n",
    "üí° **Tip**: Remember how to move up in the folder structure? `../../` goes up two folders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load in a Single File\n",
    "\n",
    "First, let's load in a single file and take a look at it. \n",
    "\n",
    "1. Read in the `Delta.csv` file as a `pandas` object.\n",
    "2. How many rows are there? How many columns?\n",
    "3. Which columns seem most informative? Are there any extra or redundant columns? \n",
    "4. Where is airline represented in the csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load in file for Delta\n",
    "single_airline = pd.read_csv(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the airline column is not present in any column, but is in the title of the csv file. Let's extract that information and add it to the DataFrame in a column called `airline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: extracting filename from path\n",
    "filename = 'airline_data/Delta.csv'.split('/')[1] \n",
    "print(filename)\n",
    "\n",
    "# Splitting the filename again to get rid of '.csv'\n",
    "filename_short = filename.split('.')[0] \n",
    "print(filename_short)\n",
    "\n",
    "# Fill in the blanks\n",
    "single_airline['airline'] = filename_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function for this. We call it `process_file()`. It takes in a filepath in an argument called `filepath`, and it returns the dataframe with the airline column added. \n",
    "\n",
    "Use the example above to set `name` variable to the split of the filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    # Add code to extract airline name and save it to a name variable\n",
    "    filename = ___\n",
    "    filename_short = ___\n",
    "    df['airline'] = name\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: Here's another filepath: `'data/US-Airways.csv'` What will be in the airline column in the output from the function below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file('../../data/airline_data/US-Airways.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Load in Multiple Files\n",
    "\n",
    "Now that we have a function, let's iterate through all of files in the directory. \n",
    "\n",
    "First, fill in the blanks below. Use `os.listdir` to loop through and print every file in the `airline_data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../../data/airline_data'\n",
    "for file in os.____(____):\n",
    "    print(______)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there is a `.txt` file in the directory, which isn't a `pandas` dataframe. This will cause an error in the dataframe processing, so let's use an `if` statement to filter out the `.txt` extension. \n",
    "\n",
    "Before implementing this, let's practice. Here's a test filename. Write a statement using the equality operator (`==`). Slice the last 3 characters of the `test_csv` variable to return `True`.\n",
    "\n",
    "üí° **Tip**: Recall slicing the last elements of a list. For instance, use `some_list[-2:]` to get the last two items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = 'delta.csv' # Expression should evaluate True\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an expression, let's create a for-loop to check if it works over the files in our folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../../data/airline_data'\n",
    "for file in os.listdir(directory):\n",
    "    if _____ # Fill in the blank to filter for files ending with `.csv`\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge: Put it all together\n",
    "\n",
    "We've got most of the pieces. Now let's put the puzzle together:\n",
    "1) In the cell below, paste the `process_file()` function we created above.\n",
    "2) Initialize an *accumulator* list called `df_list`.\n",
    "3) Paste the `for`-loop we just created to loop over the csv files in the right folder. But in the final line, instead of `print`ing the file, `append` the output to our `df_list` list.\n",
    "\n",
    "‚ö†Ô∏è **Warning**: Note that when calling `process_file()` in the for-loop, you'll need to pass the **full filepath**, not just the file name! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, look up the [documentation for Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/general_functions.html), and see if you can find a function that **concatenates** the list of DataFrames we have now. We'll save the concatenated list in a variable called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: Let's take a look at the final data frame.\n",
    "\n",
    "1. How many rows and columns are there in the total dataframe?\n",
    "2. How many unique airlines are in the dataset?\n",
    "3. How many numeric columns are there in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "\n",
    "Now that we have some data, let's take a look at some data processing steps.\n",
    "\n",
    "### 2.1 Nulls\n",
    "\n",
    "First, let's summarize the null values in the dataset. We want to see which columns have null values and how many. \n",
    "\n",
    "You recall that `.isnull()` is a method that returns `True` where there are null values and a `False` otherwise in a DataFrame. \n",
    "\n",
    "You look up finding the sum of null values in Pandas and find a suggestion to use `df.isnull().sum(axis=1)`. You try this out on your data set and get the output below. Is this the expected output? If not, how can you modify the code to find the number of null values in each column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are null values in the data set, We won't be using any of the columns with null values in the analysis, so we don't need to drop any rows from this dataset. \n",
    "\n",
    "Let's drop the following columns:\n",
    "\n",
    "* `tweet_id`\n",
    "* `airline_sentiment_confidence`\n",
    "* `negativereason_confidence`\n",
    "* `airline_sentiment_gold`\n",
    "* `airline_sentiment_gold`\n",
    "* `tweet_coord`\n",
    "* `tweet_location`\n",
    "* `user_timezone`\n",
    "\n",
    "This will make the dataset more manageable for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'Unnamed: 0',\n",
    "    'tweet_coord',\n",
    "    'tweet_id',\n",
    "    'user_timezone',\n",
    "    'tweet_created',\n",
    "    'tweet_location',\n",
    "    'negativereason_gold',\n",
    "    'airline_sentiment_gold']\n",
    "list(df)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Extraction\n",
    "\n",
    "Now let's do some basic preprocessing on the data. First, let's look at the first few rows of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a couple of simple feature extraction on the text data, including the number of words. Let's make three new columns:\n",
    "1. `word_count`: number of words in each tweet (üí° Tip: use `.split() and .len()`).\n",
    "2. `mentions` : count number of '@' symbols (üí° Tip: use `.count()`).\n",
    "\n",
    "üí° **Tip**: Remember that you can use `Series.str` to access vectorized string functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df['word_count'] = ___\n",
    "df['mentions'] = ___\n",
    "\n",
    "# Final one of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps in text preprocessing would often use tokenization or vectorization on tweets, to convert the words themselves to numerical data for preprocessing. If you are interested, check out the Python Text Analysis workshop! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Subset Tweets\n",
    "\n",
    "üîî **Question**: How many sentiment types are there in the DataFrame? \n",
    "\n",
    "For our exploratory analysis, let's start by looking just at postive/negative tweets.\n",
    "\n",
    "1. Subset the dataframe.\n",
    "2. What proportion of the tweets have a positive sentiment?\n",
    "\n",
    "What is the condition that we would use to subset the dataframe? Subset the dataframe for non-neutral tweets and save it to a dataframe called `pos_neg_df`.\n",
    "\n",
    "üí° **Tip**: You can use `!=` to check for all values not equal to a certain value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.4 Convert column to int\n",
    "\n",
    "If we want to do exploratory analysis with the \"airline_sentiment\" column we just created, we will need to convert the categorical variables (currently in string format) into numbers. We can use `.replace()` to do so. Look up the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) and fill in the arguments needed for `.replace()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_df['airline_sentiment'].replace(___, ___, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Analysis\n",
    "\n",
    "\n",
    "Now that we've done some very basic processing on the `DataFrame`, let's do some exploratory analyses on the data. \n",
    "\n",
    "###  3.1 Most Common Users, Most Frequent Airlines\n",
    "\n",
    "Let's look at the users tweeting at the airlines. Using the `DataFrame`, answer the following questions:\n",
    "\n",
    "1. How many unique users are there in the dataset? \n",
    "2. Who tweeted the most about airlines in this dataset? (**Hint**: consider `df.value_counts()`)\n",
    "3. Choose one of the users with the top five most tweets. Which airline are they tweeting about?\n",
    "\n",
    "üí° **Tip**: Users are recorded in the `name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualization\n",
    "\n",
    "Now, let's visualize some component of the data set. Use a **histogram** to visualize the `word_counts` column. Consider plotting two layers: one for negative tweets and one for positive tweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Linear Regression of Tweet Length\n",
    "\n",
    "Let's use a linear regression to look at other predictors of tweet length. Complete the steps:\n",
    "\n",
    "1. Select the numeric columns 'airline_sentiment','airline_sentiment_confidence','retweet_count','mentions', and save it as `X` (except wordcount)\n",
    "2. Select the word_count column and save as `y`\n",
    "3. Set up a linear regression and fit it to the data using `sm.OLS()`\n",
    "4. Interpret the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X = ___\n",
    "y = ___\n",
    "model = ___\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Files\n",
    "\n",
    "Finally, a `pd.DataFrame` can be exported to a `.csv` (or other filetype) using `df.to_csv()`. This is a method function built-in to every data frame.\n",
    "\n",
    "üîî **Question**:  Where does `airlines_sentiment.csv` get saved? What if you wanted to save it to the \"data\" directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_df.to_csv('airlines_sentiment.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Take-home challenge: Are Negative Tweets Longer than Positive Tweets?\n",
    "\n",
    "For those who want some more practive after the workshop, here's a challenge.\n",
    "\n",
    "Take a look at the negative and positive tweets. We are interested in the whether negative tweets are longer or shorter than positive tweets. Let's test this with a t-test.\n",
    "\n",
    "1. Subset the data into positive and negative tweets.\n",
    "2. Select the `word_count` column.\n",
    "3. Calculate the mean word count for each column. Which mean is higher?\n",
    "3. Use a t-test to compare the two sets of values from (2). What is the p-value of the result? \n",
    "4. Plot a histogram layer for both positive and negative tweet word counts. What do you notice about the distribution?\n",
    "\n",
    "üí° **Tip**: Refer to the [first section](#stats) of this notebook for an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataframe\n",
    "\n",
    "# Calculate mean\n",
    "\n",
    "\n",
    "# Run t-test\n",
    "res = sm.stats.ttest_ind(___)\n",
    "\n",
    "\n",
    "# Plot (kind = 'hist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Well done!\n",
    "\n",
    "**This concludes Python Fundamentals II!**\n",
    "\n",
    "Today's project took us through importing multiple csv files, data manipulation, and some basic visualizations and analysis of data. \n",
    "\n",
    "If you were working on this dataset, what would you potentially do next? It could be either an analysis, a new feature to include, a visualization that might help represent the data, etc.\n",
    "\n",
    "### üí° Tip: More workshops!\n",
    "\n",
    "D-Lab teaches workshops that allow you to practice more with DataFrames and visualization.\n",
    "\n",
    "- To learn more about data wrangling, check out D-Lab's [Python Data Wrangling workshop](https://github.com/dlab-berkeley/Python-Data-Wrangling).\n",
    "- To learn more about data visualization, check out D-Lab's [Python Data Visualization workshop](https://github.com/dlab-berkeley/Python-Data-Visualization)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
